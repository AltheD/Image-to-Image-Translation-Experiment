{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 数据探索 (EDA)\n",
    "- 统计数量/尺寸\n",
    "- 标签颜色模式检查\n",
    "- 随机可视化\n",
    "- 简单损坏检测\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T13:56:09.861786Z",
     "iopub.status.busy": "2025-12-15T13:56:09.861786Z",
     "iopub.status.idle": "2025-12-15T13:56:10.241753Z",
     "shell.execute_reply": "2025-12-15T13:56:10.241753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded splits: {'train': 2975, 'val': 500}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import random\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Notebook 运行目录默认在 notebooks/，需要回到项目根读取 data\n",
    "ROOT = Path(\"..\").resolve() / \"data\"\n",
    "PROCESSED = ROOT / \"processed\"\n",
    "SPLIT_FILE = ROOT / \"splits\" / \"cityscapes_split_seed42.json\"\n",
    "\n",
    "with SPLIT_FILE.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    splits = json.load(f)\n",
    "\n",
    "print(\"loaded splits:\", {k: len(v) for k, v in splits.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T13:56:10.270328Z",
     "iopub.status.busy": "2025-12-15T13:56:10.269319Z",
     "iopub.status.idle": "2025-12-15T13:56:10.289635Z",
     "shell.execute_reply": "2025-12-15T13:56:10.289083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] count: 2975, photo_dir=C:\\Users\\23208\\Desktop\\Image-to-Image-Translation-Experiment\\data\\processed\\train\\photo, label_dir=C:\\Users\\23208\\Desktop\\Image-to-Image-Translation-Experiment\\data\\processed\\train\\label\n",
      "  missing in first200: 0\n",
      "[val] count: 500, photo_dir=C:\\Users\\23208\\Desktop\\Image-to-Image-Translation-Experiment\\data\\processed\\val\\photo, label_dir=C:\\Users\\23208\\Desktop\\Image-to-Image-Translation-Experiment\\data\\processed\\val\\label\n",
      "  missing in first200: 0\n"
     ]
    }
   ],
   "source": [
    "def count_per_split(split: str):\n",
    "    files = splits[split]\n",
    "    photo_dir = PROCESSED / split / \"photo\"\n",
    "    label_dir = PROCESSED / split / \"label\"\n",
    "    print(f\"[{split}] count: {len(files)}, photo_dir={photo_dir}, label_dir={label_dir}\")\n",
    "    missing = []\n",
    "    for name in itertools.islice(files, 0, 200):  # 先抽前200个简单检查\n",
    "        stem = Path(name).stem\n",
    "        if not (photo_dir / f\"{stem}_photo.jpg\").exists():\n",
    "            missing.append(name)\n",
    "        if not (label_dir / f\"{stem}_label.png\").exists():\n",
    "            missing.append(name)\n",
    "    print(f\"  missing in first200: {len(missing)}\")\n",
    "\n",
    "count_per_split(\"train\")\n",
    "count_per_split(\"val\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T13:56:10.292656Z",
     "iopub.status.busy": "2025-12-15T13:56:10.291672Z",
     "iopub.status.idle": "2025-12-15T13:56:10.530334Z",
     "shell.execute_reply": "2025-12-15T13:56:10.530334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] size top5 (sample 400): [((256, 256), 400)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] size top5 (sample 400): [((256, 256), 400)]\n"
     ]
    }
   ],
   "source": [
    "def size_distribution(split: str, max_samples: int = 400):\n",
    "    files = splits[split]\n",
    "    photo_dir = PROCESSED / split / \"photo\"\n",
    "    sizes = []\n",
    "    sample_names = random.sample(files, min(len(files), max_samples))\n",
    "    for name in sample_names:\n",
    "        stem = Path(name).stem\n",
    "        with Image.open(photo_dir / f\"{stem}_photo.jpg\") as img:\n",
    "            sizes.append(img.size)\n",
    "    counter = Counter(sizes)\n",
    "    top = counter.most_common(5)\n",
    "    print(f\"[{split}] size top5 (sample {len(sample_names)}): {top}\")\n",
    "    return counter\n",
    "\n",
    "random.seed(42)\n",
    "train_sizes = size_distribution(\"train\")\n",
    "val_sizes = size_distribution(\"val\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T13:56:10.532205Z",
     "iopub.status.busy": "2025-12-15T13:56:10.532205Z",
     "iopub.status.idle": "2025-12-15T13:56:10.696187Z",
     "shell.execute_reply": "2025-12-15T13:56:10.696187Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23208\\AppData\\Local\\Temp\\ipykernel_13440\\948946657.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "def show_samples(split: str, k: int = 3):\n",
    "    files = splits[split]\n",
    "    photo_dir = PROCESSED / split / \"photo\"\n",
    "    label_dir = PROCESSED / split / \"label\"\n",
    "    names = random.sample(files, k)\n",
    "    fig, axes = plt.subplots(k, 2, figsize=(6, 3 * k))\n",
    "    for idx, name in enumerate(names):\n",
    "        stem = Path(name).stem\n",
    "        with Image.open(label_dir / f\"{stem}_label.png\") as lbl, Image.open(photo_dir / f\"{stem}_photo.jpg\") as img:\n",
    "            axes[idx, 0].imshow(lbl)\n",
    "            axes[idx, 0].set_title(f\"label: {name}\")\n",
    "            axes[idx, 0].axis(\"off\")\n",
    "            axes[idx, 1].imshow(img)\n",
    "            axes[idx, 1].set_title(\"photo\")\n",
    "            axes[idx, 1].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "random.seed(123)\n",
    "show_samples(\"train\", k=3)\n",
    "show_samples(\"val\", k=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T13:56:10.699249Z",
     "iopub.status.busy": "2025-12-15T13:56:10.698282Z",
     "iopub.status.idle": "2025-12-15T13:56:11.138128Z",
     "shell.execute_reply": "2025-12-15T13:56:11.138128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] corruption check on 500 samples -> bad: 0\n",
      "[val] corruption check on 200 samples -> bad: 0\n"
     ]
    }
   ],
   "source": [
    "def corruption_check(split: str, max_samples: int = 300):\n",
    "    files = splits[split]\n",
    "    photo_dir = PROCESSED / split / \"photo\"\n",
    "    label_dir = PROCESSED / split / \"label\"\n",
    "    names = random.sample(files, min(len(files), max_samples))\n",
    "    bad = []\n",
    "    for name in names:\n",
    "        stem = Path(name).stem\n",
    "        try:\n",
    "            with Image.open(photo_dir / f\"{stem}_photo.jpg\") as img:\n",
    "                img.verify()\n",
    "            with Image.open(label_dir / f\"{stem}_label.png\") as lbl:\n",
    "                lbl.verify()\n",
    "        except Exception as e:  # noqa: BLE001\n",
    "            bad.append((name, str(e)))\n",
    "    print(f\"[{split}] corruption check on {len(names)} samples -> bad: {len(bad)}\")\n",
    "    if bad:\n",
    "        print(bad[:5])\n",
    "\n",
    "random.seed(2025)\n",
    "corruption_check(\"train\", max_samples=500)\n",
    "corruption_check(\"val\", max_samples=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T13:56:11.142456Z",
     "iopub.status.busy": "2025-12-15T13:56:11.141458Z",
     "iopub.status.idle": "2025-12-15T13:56:14.447638Z",
     "shell.execute_reply": "2025-12-15T13:56:14.447638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split summary:\n",
      "train {'count': 2975, 'sizes': [((256, 256), 2975)], 'photo_modes': Counter({'RGB': 2975}), 'label_modes': Counter({'RGB': 2975})}\n",
      "val {'count': 500, 'sizes': [((256, 256), 500)], 'photo_modes': Counter({'RGB': 500}), 'label_modes': Counter({'RGB': 500})}\n",
      "unique colors sample for train:\n",
      "  679.jpg: unique colors = 17967\n",
      "  1409.jpg: unique colors = 13185\n",
      "  1090.jpg: unique colors = 10435\n",
      "unique colors sample for val:\n",
      "  440.jpg: unique colors = 16445\n",
      "  225.jpg: unique colors = 12389\n",
      "  211.jpg: unique colors = 15403\n"
     ]
    }
   ],
   "source": [
    "# 模式统计与标签颜色唯一值\n",
    "from collections import Counter\n",
    "\n",
    "summary = {}\n",
    "for split in (\"train\", \"val\"):\n",
    "    photo_dir = PROCESSED / split / \"photo\"\n",
    "    label_dir = PROCESSED / split / \"label\"\n",
    "    files = splits[split]\n",
    "    size_counter = Counter()\n",
    "    photo_modes = Counter()\n",
    "    label_modes = Counter()\n",
    "    for name in files:\n",
    "        stem = Path(name).stem\n",
    "        with Image.open(photo_dir / f\"{stem}_photo.jpg\") as p:\n",
    "            size_counter[p.size] += 1\n",
    "            photo_modes[p.mode] += 1\n",
    "        with Image.open(label_dir / f\"{stem}_label.png\") as l:\n",
    "            label_modes[l.mode] += 1\n",
    "    summary[split] = {\n",
    "        \"count\": len(files),\n",
    "        \"sizes\": size_counter.most_common(3),\n",
    "        \"photo_modes\": photo_modes,\n",
    "        \"label_modes\": label_modes,\n",
    "    }\n",
    "\n",
    "print(\"split summary:\")\n",
    "for k, v in summary.items():\n",
    "    print(k, v)\n",
    "\n",
    "# 抽样查看标签颜色数量\n",
    "random.seed(42)\n",
    "for split in (\"train\", \"val\"):\n",
    "    files = random.sample(splits[split], 3)\n",
    "    label_dir = PROCESSED / split / \"label\"\n",
    "    print(f\"unique colors sample for {split}:\")\n",
    "    for name in files:\n",
    "        stem = Path(name).stem\n",
    "        with Image.open(label_dir / f\"{stem}_label.png\") as l:\n",
    "            uniq = len(set(l.convert(\"RGB\").getdata()))\n",
    "            print(f\"  {name}: unique colors = {uniq}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T13:56:14.450645Z",
     "iopub.status.busy": "2025-12-15T13:56:14.449666Z",
     "iopub.status.idle": "2025-12-15T13:56:15.267380Z",
     "shell.execute_reply": "2025-12-15T13:56:15.267380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved summary and figures to C:\\Users\\23208\\Desktop\\Image-to-Image-Translation-Experiment\\outputs\\figures\n"
     ]
    }
   ],
   "source": [
    "# 保存统计表与可视化到项目根的 outputs/figures\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "out_dir = (ROOT.parent / \"outputs\" / \"figures\").resolve()\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def export_summary(summary_dict, path):\n",
    "    with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"split\", \"count\", \"sizes_top3\", \"photo_modes\", \"label_modes\", \"timestamp\"])\n",
    "        ts = datetime.now().isoformat(timespec=\"seconds\")\n",
    "        for split, info in summary_dict.items():\n",
    "            writer.writerow([\n",
    "                split,\n",
    "                info[\"count\"],\n",
    "                info[\"sizes\"],\n",
    "                dict(info[\"photo_modes\"]),\n",
    "                dict(info[\"label_modes\"]),\n",
    "                ts,\n",
    "            ])\n",
    "\n",
    "# 依赖上一单元生成的 summary\n",
    "export_summary(summary, out_dir / \"eda_summary.csv\")\n",
    "\n",
    "\n",
    "def save_samples(split: str, k: int, filename: str):\n",
    "    files = splits[split]\n",
    "    photo_dir = PROCESSED / split / \"photo\"\n",
    "    label_dir = PROCESSED / split / \"label\"\n",
    "    names = random.sample(files, k)\n",
    "    fig, axes = plt.subplots(k, 2, figsize=(6, 3 * k))\n",
    "    for idx, name in enumerate(names):\n",
    "        stem = Path(name).stem\n",
    "        with Image.open(label_dir / f\"{stem}_label.png\") as lbl, Image.open(photo_dir / f\"{stem}_photo.jpg\") as img:\n",
    "            axes[idx, 0].imshow(lbl)\n",
    "            axes[idx, 0].set_title(f\"label: {name}\")\n",
    "            axes[idx, 0].axis(\"off\")\n",
    "            axes[idx, 1].imshow(img)\n",
    "            axes[idx, 1].set_title(\"photo\")\n",
    "            axes[idx, 1].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_dir / filename, dpi=120)\n",
    "    plt.close(fig)\n",
    "\n",
    "random.seed(2025)\n",
    "save_samples(\"train\", k=4, filename=\"eda_samples_train.png\")\n",
    "save_samples(\"val\", k=3, filename=\"eda_samples_val.png\")\n",
    "print(\"Saved summary and figures to\", out_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行提示：\n",
    "- 在项目根目录启动 Jupyter/VS Code Notebook 运行本文件。\n",
    "- 若需全量尺寸统计，将 `max_samples` 参数调大或移除采样限制。\n",
    "- 若想保存可视化结果，可在 `show_samples` 中调用 `plt.savefig`。\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
